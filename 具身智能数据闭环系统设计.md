# 具身智能轮式家庭通用机器人数据闭环系统设计

## 目录
- [1. 设计目标与核心理念](#1-设计目标与核心理念)
- [2. 总体架构](#2-总体架构云边端四级闭环)
- [3. 端侧执行层设计](#3-端侧执行层设计传感与触发)
- [4. 数据枢纽层设计](#4-数据枢纽层设计数据治理与价值评估)
- [5. 云端训练层设计](#5-云端训练层设计大小脑协同进化)
- [6. 部署与反馈设计](#6-部署与反馈设计影子模式与多级安全闸门)
- [7. 技术栈与实施路线](#7-技术栈与实施路线)
- [8. 风险分析与应对策略](#8-风险分析与应对策略)
- [9. 总结](#9-总结)

---

## 1. 设计目标与核心理念

### 1.1 目标定义

轮式家庭通用机器人工作在开放、动态且强隐私的家庭环境中，本方案的目标是构建一套 **可持续进化的数据闭环系统**，让机器人在长期运行中持续提升以下能力：

- **任务完成能力**：从简单导航、取物，到多步骤复杂任务
- **安全与可控性**：人在回路内，确保对人、宠物和财产零伤害
- **家庭适配性**：对不同户型、家具布置、家庭成员习惯逐步自适应

可将整体目标抽象为：

$$
\text{进化速度} = \frac{\text{高价值失败与不确定性数据} \times \text{有效学习}}{\text{安全风险} + \text{隐私泄露代价}}
$$

### 1.2 核心设计原则：F.U.N. + 安全底线

我们不追求海量数据，只追求高价值数据。系统的驱动力遵循 **F.U.N. 原则**：

| 原则 | 说明 | 示例 |
|------|------|------|
| **F**ailure (失败) | 机器人卡住、撞墙、任务未完成的数据最值钱 | 抓取失败、物体掉落 |
| **U**ncertainty (不确定性) | 模型熵值高、犹豫不决的场景需要记录 | 面对玻璃茶几导航策略犹豫 |
| **N**ovelty (新颖性) | 向量库中未出现过的场景 | 首次遇到缠绕的数据线 |

**五大设计原则**：

1. **安全优先于性能**：宁可任务失败，也不允许出现安全事故
2. **隐私内生**：从采集、存储到训练全链路内建隐私保护
3. **少而精的数据**：聚焦高价值失败、不确定、新颖场景，而非盲目追求数据规模
4. **分层自治**：云、边、端各自自治又协同，避免单点故障和过度依赖网络
5. **可回滚与可审计**：所有策略更新可追溯、可回退，关键决策路径可解释

### 1.3 典型应用任务

| 任务类型 | 典型场景 | 关键能力要求 |
|----------|----------|--------------|
| 安全导航 | 在客厅、厨房、卧室间平稳移动 | 避障、路径规划、动态物体躲避 |
| 物体拾取与递送 | 从茶几上拿水杯到餐桌 | 物体识别、抓取规划、力控制 |
| 环境整理 | 收集客厅散落的玩具到收纳盒 | 场景理解、多物体操作序列 |
| 紧急辅助 | 向家人递送药物或物品 | 快速响应、可靠执行 |

---

## 2. 总体架构：云边端四级闭环

系统采用"**云端训练层—数据枢纽层—端侧执行层—家庭物理环境**"的四级架构，形成可观测、可控、可演进的数据闭环。

### 2.1 架构图

```
┌─────────────────────────────────────────────────────────────────┐
│                     云端训练层 (Cloud Brain)                     │
│   世界模型训练    VLA模型优化    仿真验证平台    评估与发布       │
└───────────────────────────┬─────────────────────────────────────┘
                            │ 模型与策略包下发
                            ▼
┌─────────────────────────────────────────────────────────────────┐
│                    数据枢纽层 (Data Engine)                      │
│   数据接收  价值评估  隐私脱敏校验  向量记忆库  训练调度          │
└───────────────────────────┬─────────────────────────────────────┘
                            │ 高价值数据与触发信号
                            ▼
┌─────────────────────────────────────────────────────────────────┐
│                    端侧执行层 (Robot Edge)                       │
│   实时感知  决策推理  安全监控  智能触发  本地缓存               │
└───────────────────────────┬─────────────────────────────────────┘
                            │ 物理交互与人机交互
                            ▼
┌─────────────────────────────────────────────────────────────────┐
│                   家庭物理环境 (Real World)                      │
│   家具布局  人与宠物  环境变化  任务需求                         │
└─────────────────────────────────────────────────────────────────┘
```

### 2.2 各层职责

| 层级 | 核心职责 | 关键技术 |
|------|----------|----------|
| **云端训练层** | 汇总高价值数据，训练和评估世界模型、VLA大脑和控制策略 | PyTorch, Isaac Sim, vLLM |
| **数据枢纽层** | 数据价值打分、脱敏校验、向量索引构建和训练任务调度 | FastAPI, Milvus, MinIO |
| **端侧执行层** | 运行实时推理与控制逻辑，执行任务并进行安全监控和数据采集触发 | ROS 2, TensorRT |
| **家庭物理环境** | 提供真实任务与约束，是闭环的最终评判者 | — |

### 2.3 闭环流程总览

一个完整的数据闭环从任务发起到模型更新可划分为八个阶段：

```
┌──────────────────────────────────────────────────────────────────────┐
│                        数据闭环流程                                   │
├──────────────────────────────────────────────────────────────────────┤
│  ① 策略下发 ──→ ② 任务生成与感知 ──→ ③ 决策与执行                   │
│       ↑                                        │                     │
│       │                                        ▼                     │
│  ⑧ 指标监控     ④ 智能数据触发 ←────────────────                    │
│  与再触发              │                                             │
│       ↑                ▼                                             │
│       │         ⑤ 数据上传与治理                                     │
│       │                │                                             │
│       │                ▼                                             │
│  ⑦ 影子模式    ⑥ 模型训练与仿真验证                                 │
│  与灰度发布 ←─────────────                                           │
└──────────────────────────────────────────────────────────────────────┘
```

**各阶段说明**：

1. **策略下发**：云端发布新的模型版本和安全规则，通过数据枢纽分发到端侧
2. **任务生成与感知**：用户通过语音或应用发出任务，机器人通过多模态传感器感知环境
3. **决策与执行**：VLA大脑提供高层意图和技能序列，小脑策略控制轮式底盘与操作机构执行
4. **智能数据触发**：当出现失败、不确定或新颖场景时，端侧触发数据录制
5. **数据上传与治理**：高价值片段经过端侧脱敏后上传到数据枢纽，进行价值评估和索引
6. **模型训练与仿真验证**：云端利用新数据迭代训练，在仿真和回放环境中充分验证
7. **影子模式与灰度发布**：端侧以影子模式运行新策略，比较新旧策略差异，符合门槛后逐步灰度
8. **指标监控与再触发**：实时监控安全、性能和体验指标，根据趋势自动触发下一轮训练周期

---

## 3. 端侧执行层设计：传感与触发

### 3.1 传感器与本体配置

针对轮式家庭通用机器人的特性，推荐以下传感与本体配置：

#### 视觉传感器

| 传感器 | 位置 | 用途 | 家庭场景特殊考量 |
|--------|------|------|------------------|
| RGB-D相机 | 头部 | 环境建模、物体识别 | 防眩光处理（应对窗户、镜子） |
| 广角相机/环视摄像头 | 前向 | 优化导航视野，减少盲区 | 低功耗模式待机，仅关键帧处理 |
| 微距相机 | 腕部/末端 | 支撑精细操作和抓取 | 高帧率捕捉抓取细节 |

#### 距离与避障传感器

| 传感器 | 用途 | 特殊考量 |
|--------|------|----------|
| 低位二维Lidar | 避障和建图 | 优化高度，对桌腿和低矮障碍敏感 |
| 超声波传感器 | 透明物体检测 | 专为玻璃门、落地窗设计 |
| 红外传感器 | 补足镜面识别 | 应对家庭常见的镜面家具 |

#### 本体状态传感器

| 传感器 | 用途 |
|--------|------|
| 轮子电机编码器 | 识别卡滞、打滑等异常 |
| 电流传感器 | 监测电机过载 |
| IMU | 识别坡度和台阶 |
| 防跌落传感器 | 防止跌落 |
| 碰撞条传感器(Bumper) | 提供触觉接触信号 |

#### 人机交互传感器

| 传感器 | 用途 |
|--------|------|
| 麦克风阵列 | 语音指令和声源定位 |
| 扬声器与指示灯 | 向用户反馈状态与警告 |

### 3.2 智能数据触发策略

端侧**不做全量录制**，而是围绕失败、不确定和新颖三类信号构建触发策略。

#### 触发类型定义

| 触发类型 | 触发条件 | 优先级 |
|----------|----------|--------|
| **安全触发** | 碰撞、急停、轮子卡死、跌落风险 | 最高 (0.9) |
| **人类干预触发** | 用户语音打断、手动遥控接管、强制停止 | 高 (0.95) |
| **失败触发** | 任务超时、子任务未完成、物体抓取失败 | 高 (0.85) |
| **不确定性触发** | 决策熵值较高，模型在下一步动作上显著犹豫 | 中 (0.8) |
| **新颖性触发** | 当前视景与历史经验向量库差异较大 | 中 (0.75) |

#### 端侧判定逻辑示例

```python
from typing import Tuple
from dataclasses import dataclass

@dataclass
class RobotState:
    near_collision: bool
    wheel_stuck: bool
    emergency_stop: bool
    model_uncertainty: float
    human_takeover: bool
    failure_code: str
    novelty_score: float

class DataTrigger:
    """智能数据触发器"""
    
    def __init__(self, uncertainty_threshold: float = 0.7, history_size: int = 10) -> None:
        self.uncertainty_threshold = uncertainty_threshold
        self.recent_failures: list[str] = []
        self.history_size = history_size

    def record_failure(self, failure_code: str) -> None:
        """记录失败历史"""
        self.recent_failures.append(failure_code)
        if len(self.recent_failures) > self.history_size:
            self.recent_failures.pop(0)

    def should_record(self, state: RobotState) -> Tuple[bool, str, float]:
        """
        判断是否应该触发数据录制
        
        Returns:
            Tuple[是否触发, 触发类型, 置信度]
        """
        # 主动触发1：安全事件（最高优先级）
        if state.near_collision or state.wheel_stuck or state.emergency_stop:
            return True, "SAFETY_EVENT", 0.9

        # 主动触发2：人类干预
        if state.human_takeover:
            return True, "HUMAN_TAKEOVER", 0.95

        # 主动触发3：高不确定性
        if state.model_uncertainty > self.uncertainty_threshold:
            return True, "HIGH_UNCERTAINTY", 0.8

        # 主动触发4：重复失败
        repeated_failure_count = self.recent_failures.count(state.failure_code)
        if repeated_failure_count >= 3:
            return True, "REPEATED_FAILURE", 0.85

        # 主动触发5：新颖场景
        if state.novelty_score > 0.7:
            return True, "NOVEL_SCENE", 0.75

        return False, "", 0.0
```

### 3.3 端侧数据封装与缓冲

#### 多模态时间同步

以统一时间戳聚合所有传感器数据：

```python
@dataclass
class SyncedSensorFrame:
    """同步的多模态传感器帧"""
    timestamp_ns: int          # 纳秒级时间戳
    rgb_image: bytes           # RGB图像
    depth_image: bytes         # 深度图像
    lidar_scan: list[float]    # 激光扫描数据
    imu_data: dict             # IMU数据
    wheel_odom: dict           # 轮式里程计
    motor_current: list[float] # 电机电流
    audio_chunk: bytes         # 音频数据
```

#### 片段封装格式

- 使用 `rosbag2` 录制并选择 `mcap` 作为底层存储格式
- 支持跨语言回放与离线处理
- 保证回放一致性

#### 循环缓冲机制

```python
from collections import deque

class CircularBuffer:
    """循环缓冲区，用于保留触发前后的数据"""
    
    def __init__(self, pre_trigger_seconds: float = 10.0, 
                 post_trigger_seconds: float = 5.0,
                 frame_rate: int = 30):
        self.pre_buffer_size = int(pre_trigger_seconds * frame_rate)
        self.post_buffer_size = int(post_trigger_seconds * frame_rate)
        self.buffer = deque(maxlen=self.pre_buffer_size)
        
    def add_frame(self, frame: SyncedSensorFrame) -> None:
        """添加新帧到缓冲区"""
        self.buffer.append(frame)
    
    def get_episode_on_trigger(self) -> list[SyncedSensorFrame]:
        """触发时获取完整片段"""
        return list(self.buffer)
```

### 3.4 端侧隐私保护机制

隐私保护原则是"**原始敏感数据不出家**"：

#### 数据分级策略

| 等级 | 数据类型 | 处理方式 |
|------|----------|----------|
| **L1** | 原始传感器流 | 仅用于实时控制，不落盘，仅在内存短暂存在 |
| **L2** | 脱敏关键帧与少量视频片段 | 仅在触发时短暂缓存并上传 |
| **L3** | 结构化元数据 | 位姿序列、任务状态、触发类型等，可常态上传 |

#### 端侧视觉脱敏

```python
from typing import Tuple
import numpy as np

class PrivacyProtector:
    """端侧隐私保护处理器"""
    
    def __init__(self):
        self.face_detector = self._load_face_detector()
        self.screen_detector = self._load_screen_detector()
        
    def anonymize_frame(self, frame: np.ndarray) -> Tuple[np.ndarray, dict]:
        """
        对视频帧进行隐私脱敏
        
        Returns:
            脱敏后的图像, 脱敏区域元数据
        """
        anonymized = frame.copy()
        metadata = {"anonymized_regions": []}
        
        # 检测并模糊人脸
        face_regions = self.face_detector.detect(frame)
        for region in face_regions:
            anonymized = self._apply_blur(anonymized, region)
            metadata["anonymized_regions"].append({
                "type": "face", 
                "bbox": region
            })
        
        # 检测并模糊屏幕/文字
        screen_regions = self.screen_detector.detect(frame)
        for region in screen_regions:
            anonymized = self._apply_blur(anonymized, region)
            metadata["anonymized_regions"].append({
                "type": "screen", 
                "bbox": region
            })
            
        return anonymized, metadata
    
    def _apply_blur(self, image: np.ndarray, region: tuple) -> np.ndarray:
        """对指定区域应用高斯模糊"""
        x1, y1, x2, y2 = region
        roi = image[y1:y2, x1:x2]
        blurred_roi = cv2.GaussianBlur(roi, (99, 99), 30)
        image[y1:y2, x1:x2] = blurred_roi
        return image
```

#### 用户控制接口

- **物理隐私开关**：一键关闭摄像头和麦克风
- **安全模式配置页面**：允许用户调整上传频率和敏感区域
- **数据删除接口**：支持用户导出与删除个人数据

---

## 4. 数据枢纽层设计：数据治理与价值评估

数据枢纽层运行在家庭网关或私有云环境，是数据治理的核心。

### 4.1 数据摄取与存储

#### 数据摄取服务

```python
from fastapi import FastAPI, BackgroundTasks, UploadFile
from celery import Celery
import asyncio

app = FastAPI(title="Data Engine API")
celery_app = Celery("tasks", broker="redis://localhost:6379/0")

@app.post("/api/v1/episodes/ingest")
async def ingest_episode(
    file: UploadFile,
    robot_id: str,
    trigger_type: str,
    trigger_confidence: float,
    background_tasks: BackgroundTasks
):
    """
    接收端侧上传的任务片段
    """
    # 1. 快速验证和暂存
    temp_path = await save_temporary(file, robot_id)
    
    # 2. 后台异步处理
    background_tasks.add_task(
        process_episode_pipeline,
        temp_path,
        robot_id,
        trigger_type,
        priority=trigger_confidence
    )
    
    return {
        "status": "accepted",
        "episode_id": generate_episode_id(),
        "priority": trigger_confidence
    }

@celery_app.task
def process_episode_pipeline(file_path: str, robot_id: str, 
                             trigger_type: str, priority: float):
    """异步处理流水线"""
    # 根据优先级调整处理顺序
    if priority > 0.8:
        high_priority_processing(file_path)
    else:
        standard_processing(file_path)
```

#### 对象存储布局

| 对象前缀 | 内容 | 说明 |
|----------|------|------|
| `episodes/raw/{robot_id}/{date}/{episode_id}.mcap` | 脱敏后的原始片段 | 仅触发事件上传 |
| `episodes/derived/{robot_id}/{date}/{episode_id}/` | 关键帧、轨迹、切片特征 | 供训练与检索 |
| `labels/{episode_id}.json` | 自动/人工标注结果 | 可多版本 |
| `manifests/{dataset_id}.json` | 数据集清单 | 固定样本集合与哈希 |

### 4.2 数据价值评估

对每个任务片段计算家庭场景价值分数，用于筛选训练数据：

$$
\text{价值分数} = \alpha \cdot \text{失败严重性} + \beta \cdot \text{新颖性} + \gamma \cdot \text{不确定性} + \delta \cdot \text{人类偏好}
$$

#### 权重配置

| 维度 | 权重 | 计算方式 | 示例 |
|------|------|----------|------|
| **失败严重性** | 0.4 | 基于任务中断类型与恢复成本 | 打翻食物(0.9) > 轻微碰撞(0.3) |
| **新颖性** | 0.3 | 当前状态嵌入与历史向量库的余弦距离 | 首次遇到"缠绕的数据线" |
| **不确定性** | 0.2 | 多个策略模型预测的动作分歧度 | 面对玻璃茶几导航犹豫 |
| **人类偏好** | 0.1 | 显式评分与隐式干预频率 | 用户说"太吵了" |

#### 价值评估实现

```python
from dataclasses import dataclass
from typing import Optional

@dataclass
class EpisodeMetadata:
    episode_id: str
    failure_type: str
    mean_uncertainty: float
    user_feedback_score: float
    key_frame_embedding: list[float]

class ValueEvaluator:
    """数据价值评估引擎"""
    
    def __init__(self, vector_db_client):
        self.vector_db = vector_db_client
        self.severity_map = {
            "NONE": 0.0,
            "PATH_DETOUR": 0.2,
            "MINOR_COLLISION": 0.5,
            "GRASP_FAILURE": 0.6,
            "OBJECT_DROP": 0.7,
            "OBJECT_DAMAGED": 0.9,
        }
    
    async def evaluate_episode_value(self, episode: EpisodeMetadata) -> float:
        """
        计算Episode的综合价值分数
        """
        # 1. 失败严重性分数 (权重 0.4)
        severity_score = self.severity_map.get(episode.failure_type, 0.0)
        
        # 2. 不确定性分数 (权重 0.2)
        uncertainty_score = max(0.0, min(1.0, episode.mean_uncertainty))
        
        # 3. 新颖性分数 (权重 0.3) - 通过向量库计算
        nearest_distance = await self.vector_db.search_nearest_distance(
            episode.key_frame_embedding
        )
        novelty_score = max(0.0, min(1.0, nearest_distance))
        
        # 4. 人类偏好分数 (权重 0.1)
        preference_score = max(0.0, min(1.0, episode.user_feedback_score))
        
        # 综合价值分数
        value = (
            0.4 * severity_score +
            0.3 * novelty_score +
            0.2 * uncertainty_score +
            0.1 * preference_score
        )
        
        return value
```

### 4.3 数据契约：Episode 元数据结构

为保证端侧、数据枢纽与云端训练解耦，统一 Episode 数据契约：

```python
from dataclasses import dataclass
from typing import List, Optional
from datetime import datetime

@dataclass
class EpisodeContract:
    """Episode数据契约"""
    
    # 标识字段
    episode_id: str
    robot_id: str
    home_id_hash: str
    timestamp_start: datetime
    timestamp_end: datetime
    timezone: str
    
    # 触发字段
    trigger_type: str           # SAFETY_EVENT, HIGH_UNCERTAINTY, etc.
    trigger_confidence: float
    pre_buffer_seconds: float
    post_buffer_seconds: float
    
    # 任务字段
    task_type: str
    task_text: Optional[str]
    skill_chain: List[str]
    subtask_status: dict
    
    # 安全字段
    near_collision: bool
    collision: bool
    emergency_stop: bool
    human_takeover: bool
    takeover_reason: Optional[str]
    
    # 质量字段
    sensor_health: dict
    frame_drop_rate: float
    calibration_version: str
    
    # 隐私字段
    privacy_level: int          # 1, 2, 3
    anonymization_methods: List[str]
    consent_flags: dict
    
    # 学习字段
    mean_uncertainty: float
    novelty_score: float
    value_score: float
    model_version: str
```

### 4.4 场景记忆与技能检索 (RAG)

数据枢纽层构建面向机器人的长期记忆系统，为决策和训练提供经验检索能力：

```python
from pymilvus import connections, Collection, FieldSchema, CollectionSchema, DataType

class SceneMemoryBank:
    """场景记忆库 - 基于向量数据库的RAG系统"""
    
    def __init__(self, host: str = "localhost", port: int = 19530):
        connections.connect(host=host, port=str(port))
        self._init_collection()
    
    def _init_collection(self):
        """初始化向量集合"""
        fields = [
            FieldSchema(name="episode_id", dtype=DataType.VARCHAR, max_length=64, is_primary=True),
            FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=768),
            FieldSchema(name="scene_description", dtype=DataType.VARCHAR, max_length=1024),
            FieldSchema(name="task_type", dtype=DataType.VARCHAR, max_length=64),
            FieldSchema(name="failure_type", dtype=DataType.VARCHAR, max_length=64),
            FieldSchema(name="solution", dtype=DataType.VARCHAR, max_length=2048),
            FieldSchema(name="outcome", dtype=DataType.VARCHAR, max_length=16),
        ]
        schema = CollectionSchema(fields, description="Home robot scene memory")
        self.collection = Collection("home_scenarios", schema)
        
    def store_episode(self, episode_id: str, embedding: list, 
                      description: str, task_type: str,
                      failure_type: str, solution: str, outcome: str):
        """存储失败/成功案例"""
        self.collection.insert([
            [episode_id],
            [embedding],
            [description],
            [task_type],
            [failure_type],
            [solution],
            [outcome]
        ])
    
    def retrieve_similar_experiences(self, current_embedding: list, 
                                     top_k: int = 3,
                                     prefer_success: bool = True) -> list:
        """
        检索相似场景的历史经验
        
        Args:
            current_embedding: 当前场景的向量表示
            top_k: 返回结果数量
            prefer_success: 是否优先返回成功案例
        """
        expr = "outcome == 'success'" if prefer_success else None
        
        results = self.collection.search(
            data=[current_embedding],
            anns_field="embedding",
            param={"metric_type": "L2", "params": {"nprobe": 10}},
            limit=top_k,
            expr=expr,
            output_fields=["scene_description", "solution", "outcome"]
        )
        
        return [{
            "episode_id": hit.id,
            "distance": hit.distance,
            "description": hit.entity.get("scene_description"),
            "solution": hit.entity.get("solution"),
            "outcome": hit.entity.get("outcome")
        } for hit in results[0]]
```

---

## 5. 云端训练层设计：大小脑协同进化

### 5.1 模型架构：分层控制

```
                           ┌─────────────────────┐
                           │    用户指令层       │
                           │ (自然语言理解)      │
                           └──────────┬──────────┘
                                      ▼
┌───────────────────┐    ┌─────────────────────┐    ┌─────────────────────┐
│  感知模块         │    │      大脑 (VLA)      │    │      小脑 (Policy)   │
│ • 视觉编码器      │───▶│ • 任务规划          │───▶│ • 导航控制器        │
│ • 语音识别        │    │ • 语义理解          │    │ • 操作技能库        │
│ • 环境重建        │    │ • 世界模型          │    │ • 异常处理          │
└───────────────────┘    └─────────────────────┘    └──────────┬──────────┘
                                                               ▼
                                                      ┌─────────────────────┐
                                                      │      执行层         │
                                                      │ • 电机控制          │
                                                      │ • 安全监控          │
                                                      └─────────────────────┘
```

### 5.2 大脑模型 (VLA)

**Vision-Language-Action 模型**负责高层规划与语义理解：

| 组件 | 技术选型 | 说明 |
|------|----------|------|
| 基座模型 | Qwen-VL / OpenVLA | 中文场景优化 |
| 服务化 | vLLM | 支持高并发推理 |
| 微调方式 | LoRA | 降低计算成本 |

**输入输出示例**：

```
输入: "把冰箱里的牛奶放到餐桌上" + 实时视觉

输出: 可执行的技能链
  1. 导航至厨房
  2. 打开冰箱门
  3. 识别并抓取牛奶
  4. 关闭冰箱门
  5. 导航至餐桌
  6. 放置牛奶
```

### 5.3 小脑模型 (Policy Controller)

**运动控制器**负责底层执行：

| 功能模块 | 技术方案 | 应用场景 |
|----------|----------|----------|
| 导航控制 | 分层强化学习 (RL) | 全局路径规划 + 局部动态避障 |
| 操作控制 | Diffusion Policy | 柔顺操作轨迹学习 |
| 恢复控制 | Recovery Policy | 从失败状态恢复 |
| 安全层 | 规则+学习双保险 | 确保底线安全 |

### 5.4 家庭世界模型

学习家庭场景中物体的物理属性与交互效果：

```python
class HomeWorldModel:
    """家庭场景世界模型"""
    
    def __init__(self):
        self.physics_predictor = self._load_physics_model()
        self.object_properties = self._load_object_db()
    
    def predict_interaction(self, action: str, target_object: str) -> dict:
        """
        预测动作与物体的交互效果
        
        Args:
            action: 动作类型 (push, grasp, place, etc.)
            target_object: 目标物体
        
        Returns:
            预测的交互结果
        """
        obj_props = self.object_properties.get(target_object, {})
        
        # 预测物理效果
        prediction = self.physics_predictor.predict({
            "action": action,
            "mass": obj_props.get("mass", 1.0),
            "friction": obj_props.get("friction", 0.5),
            "fragility": obj_props.get("fragility", 0.0)
        })
        
        return {
            "expected_outcome": prediction["outcome"],
            "risk_level": prediction["risk"],
            "confidence": prediction["confidence"]
        }
```

### 5.5 训练数据构建

#### 真实数据

- 来自端侧采集的片段，通过数据枢纽脱敏和价值评估之后成为训练样本
- 对典型失败片段补充人工标签或利用多模态模型生成弱标签

#### 仿真数据

- 利用 NVIDIA Isaac Sim 构造大规模随机化场景
- 场景变化：不同家具布局、光照条件、临时障碍
- 危险场景优先在仿真中探索：陡坡、湿滑地面等

### 5.6 训练与评估流程

```python
class TrainingPipeline:
    """训练流水线"""
    
    def __init__(self, config: dict):
        self.config = config
        self.data_loader = DataLoader(config["data_path"])
        self.model = self._init_model()
        self.evaluator = ModelEvaluator()
    
    def train_iteration(self, dataset_manifest: str):
        """执行一轮训练迭代"""
        
        # 1. 加载数据集
        train_data = self.data_loader.load_from_manifest(dataset_manifest)
        
        # 2. 数据增强
        augmented_data = self._augment_data(train_data)
        
        # 3. 模型训练
        self.model.train(augmented_data)
        
        # 4. 评估
        eval_results = self._evaluate_model()
        
        return eval_results
    
    def _evaluate_model(self) -> dict:
        """模型评估"""
        results = {}
        
        # 回放真实片段评估
        results["replay_eval"] = self.evaluator.replay_evaluation(
            self.model, 
            self.config["replay_episodes"]
        )
        
        # 仿真压力测试
        results["sim_eval"] = self.evaluator.simulation_evaluation(
            self.model,
            num_scenarios=1000
        )
        
        # 与旧模型对比
        results["comparison"] = self.evaluator.compare_with_baseline(
            self.model,
            self.config["baseline_model"]
        )
        
        return results
```

### 5.7 数据与模型版本化

| 版本类型 | 内容 | 追溯信息 |
|----------|------|----------|
| 数据集版本 | episode_id 列表、文件哈希、派生特征版本 | 支持可重复训练 |
| 模型版本 | 模型参数、配置、支持的任务范围 | 训练数据集版本、超参、基座模型版本 |
| 发布版本 | 端侧兼容性、安全边界说明 | 完整追溯链路 |

---

## 6. 部署与反馈设计：影子模式与多级安全闸门

### 6.1 五级部署流程

新的模型版本从云端到端侧的发布过程分为五个阶段：

```
┌─────────────────────────────────────────────────────────────────┐
│                        部署安全闸门                              │
├─────────────────────────────────────────────────────────────────┤
│  阶段1: 仿真验证     → 1000+随机场景测试，通过率>95%            │
│            ↓                                                    │
│  阶段2: 回放验证     → 真实片段离线回放，比较决策差异            │
│            ↓                                                    │
│  阶段3: 影子模式     → 真机运行但不控制，记录预测vs实际          │
│            ↓                                                    │
│  阶段4: 安全区验证   → 限定区域测试，人类监护员监控              │
│            ↓                                                    │
│  阶段5: 灰度发布     → 1%→10%→50%→100%，每周评估指标            │
└─────────────────────────────────────────────────────────────────┘
```

#### 阶段详解

| 阶段 | 验证内容 | 通过条件 | 回退条件 |
|------|----------|----------|----------|
| **仿真验证** | 随机场景测试 | 通过率 > 95% | 任何严重失败 |
| **回放验证** | 历史片段回放 | 决策一致性 > 90% | 出现新的危险决策 |
| **影子模式** | 并行推理对比 | 新模型预测更优 | 预测偏差过大 |
| **安全区验证** | 限定区域真实测试 | 零安全事故 | 任何碰撞事件 |
| **灰度发布** | 分批推送 | 指标持续改善 | 指标退化 > 5% |

### 6.2 影子模式实现

```python
class ShadowModeRunner:
    """影子模式运行器"""
    
    def __init__(self, current_model, new_model, threshold: float = 0.3):
        self.current_model = current_model
        self.new_model = new_model
        self.threshold = threshold
        self.comparison_log = []
    
    def run_shadow_inference(self, observation: dict) -> dict:
        """
        执行影子模式推理
        
        Returns:
            当前模型的动作（实际执行）
        """
        # 当前模型推理（实际执行）
        current_action = self.current_model.predict(observation)
        
        # 新模型推理（仅记录，不执行）
        new_action = self.new_model.predict(observation)
        
        # 记录对比结果
        comparison = {
            "timestamp": time.time(),
            "observation_hash": hash(str(observation)),
            "current_action": current_action,
            "new_action": new_action,
            "action_difference": self._compute_difference(current_action, new_action)
        }
        self.comparison_log.append(comparison)
        
        # 如果差异过大，记录警告
        if comparison["action_difference"] > self.threshold:
            self._log_warning(comparison)
        
        return current_action
    
    def get_evaluation_report(self) -> dict:
        """生成评估报告"""
        differences = [c["action_difference"] for c in self.comparison_log]
        
        return {
            "total_samples": len(self.comparison_log),
            "mean_difference": np.mean(differences),
            "max_difference": np.max(differences),
            "within_threshold_rate": sum(d < self.threshold for d in differences) / len(differences),
            "recommendation": "APPROVE" if np.mean(differences) < self.threshold * 0.5 else "REVIEW"
        }
```

### 6.3 在线监控指标

#### 安全指标

| 指标 | 定义 | 告警阈值 |
|------|------|----------|
| 碰撞次数 | 每日碰撞事件数量 | > 3次/天 |
| 急停频率 | 急停触发次数/运行小时 | > 0.5次/小时 |
| 人类接管率 | 人类接管任务数/总任务数 | > 15% |
| 安全边界触发 | 接近安全边界的次数 | > 10次/天 |

#### 性能指标

| 指标 | 定义 | 目标值 |
|------|------|--------|
| 任务成功率 | 成功完成任务数/总任务数 | > 85% |
| 平均完成时间 | 任务平均耗时 | 持续优化 |
| 能耗效率 | 完成单位任务的能耗 | 持续优化 |

#### 学习指标

| 指标 | 定义 | 期望趋势 |
|------|------|----------|
| 不确定性均值 | 模型预测的平均不确定性 | 下降 |
| 同类错误率 | 相同类型错误的发生率 | 下降 |
| 新颖场景覆盖 | 向量库新增场景数量 | 增长 |

### 6.4 闭环触发条件

当以下任一条件满足时，自动触发新训练周期：

| 触发类型 | 条件 | 优先级 |
|----------|------|--------|
| **失败率触发** | 同类任务失败率 > 15% 持续 7 天 | 高 |
| **接管率触发** | 人类接管率相对上周 +20% | 高 |
| **安全事件触发** | 急停次数 > P95 历史分位 | 最高 |
| **环境变化触发** | 新颖性均值显著上升 | 中 |
| **用户反馈触发** | 低评分集中出现 | 中 |

### 6.5 回滚与熔断机制

```python
class SafetyController:
    """安全控制器 - 回滚与熔断"""
    
    def __init__(self, model_manager, metrics_monitor):
        self.model_manager = model_manager
        self.metrics = metrics_monitor
        self.stable_versions = []  # 保留最近两个稳定版本
    
    def check_and_rollback(self) -> bool:
        """检查指标并决定是否回滚"""
        current_metrics = self.metrics.get_current()
        
        # 检查安全指标
        if current_metrics["collision_rate"] > self.COLLISION_THRESHOLD:
            self._trigger_rollback("collision_rate_exceeded")
            return True
        
        if current_metrics["human_takeover_rate"] > self.TAKEOVER_THRESHOLD:
            self._trigger_rollback("takeover_rate_exceeded")
            return True
        
        return False
    
    def _trigger_rollback(self, reason: str):
        """执行回滚"""
        previous_stable = self.stable_versions[-1]
        self.model_manager.rollback_to(previous_stable)
        self._notify_team(f"自动回滚触发: {reason}")
    
    def enter_conservative_mode(self):
        """进入保守模式（熔断）"""
        self.model_manager.apply_conservative_policy({
            "max_speed": 0.3,           # 降速50%
            "safety_distance": 0.8,     # 扩大安全距离
            "require_confirmation": True # 关键动作需确认
        })
```

---

## 7. 技术栈与实施路线

### 7.1 技术栈选型

| 层级 | 推荐技术栈 | 说明 |
|------|------------|------|
| **端侧执行层** | ROS 2 Humble, TensorRT, Jetson Orin | 实时感知与控制 |
| **数据枢纽层** | FastAPI + AsyncIO, Milvus, MinIO, Celery | 异步数据治理与向量检索 |
| **云端训练层** | PyTorch, vLLM, LlamaFactory (LoRA) | 模型训练与高效推理 |
| **仿真平台** | NVIDIA Isaac Sim | 高保真家庭场景仿真 |
| **监控可视化** | Prometheus, Grafana | 指标监控与可视化 |
| **容器编排** | Docker, Kubernetes | 服务化部署 |

### 7.2 分阶段实施路线图

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                           90天实施路线图                                    │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  阶段一：最小可行闭环 (Day 1-30)                                           │
│  ├─ 目标：安全导航 + 数据触发 + 基础回传                                   │
│  ├─ 产出：                                                                  │
│  │   • 端侧碰撞触发机制                                                    │
│  │   • FastAPI数据接收服务                                                  │
│  │   • Docker化基础流水线                                                   │
│  │   • 从数据触发到上传的完整链路                                          │
│  └─ 里程碑：首次跑通 "采集→上传→存储" 闭环                                 │
│                                                                             │
│  阶段二：RAG记忆系统 (Day 31-60)                                           │
│  ├─ 目标：场景检索 + 自动标注 + 价值评估                                   │
│  ├─ 产出：                                                                  │
│  │   • Milvus向量库部署                                                     │
│  │   • CLIP/Qwen-VL场景编码                                                 │
│  │   • 价值评分引擎                                                         │
│  │   • 隐私保护中间件                                                       │
│  └─ 里程碑：实现 "相似场景检索" 功能                                       │
│                                                                             │
│  阶段三：分层控制架构 (Day 61-90)                                          │
│  ├─ 目标：VLA大脑 + 影子模式 + 仿真验证                                    │
│  ├─ 产出：                                                                  │
│  │   • vLLM服务化部署                                                       │
│  │   • 影子模式验证机制                                                     │
│  │   • Isaac Sim仿真测试集                                                  │
│  │   • 灰度发布流程                                                         │
│  └─ 里程碑：完成首轮 "训练→验证→部署" 循环                                 │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 7.3 长期演进路线

| 阶段 | 时间周期 | 目标 | 关键里程碑 |
|------|----------|------|------------|
| **阶段一** | 0-6个月 | 安全导航闭环 | 零碰撞导航，最小闭环跑通 |
| **阶段二** | 6-12个月 | 简单操作闭环 | 拾取与递送标准物品 |
| **阶段三** | 12个月+ | 复杂任务闭环 | 多步骤长周期任务 |

---

## 8. 风险分析与应对策略

### 8.1 隐私与合规风险

| 风险点 | 应对策略 | 备份方案 |
|--------|----------|----------|
| 家庭环境包含大量敏感信息 | 端侧完成不可逆脱敏，仅上传必要信息 | 本地小型模型处理敏感任务 |
| 数据使用合规性 | 清晰的数据使用和保留策略 | 支持用户导出与删除 |
| 人脸、屏幕内容泄露 | 实时模糊处理 | 物理隐私开关 |

### 8.2 仿真与现实差异 (Sim2Real)

| 风险点 | 应对策略 | 备份方案 |
|--------|----------|----------|
| 仿真中表现良好的策略在现实中不稳定 | 真实数据作为训练主数据源 | 建立 Sim-Real 误差模型 |
| 物理参数不匹配 | 域随机化 (Domain Randomization) | 在线自适应调整 |
| 长尾场景覆盖不足 | 持续收集真实失败案例 | 人工构造极端场景 |

### 8.3 闭环噪声累积

| 风险点 | 应对策略 | 备份方案 |
|--------|----------|----------|
| 数据质量和评估体系不足导致模型偏向错误方向 | 定期使用早期稳定版本作为对照 | 保留高质量原始数据作为固定基准集 |
| 标注错误传播 | 多模型交叉验证 | 人工审核高价值样本 |
| 分布漂移 | 监控数据分布变化 | 周期性重训练 |

### 8.4 硬件与运维风险

| 风险点 | 应对策略 | 备份方案 |
|--------|----------|----------|
| 传感器漂移、硬件老化 | 定期标定与自检 | 冗余传感器设计 |
| 网络不稳定 | 断网容忍设计 | 本地缓存 + 批量上传 |
| 计算资源不足 | 模型量化与优化 | 云端卸载部分推理 |

### 8.5 家庭场景特殊挑战

| 挑战 | 场景描述 | 技术解法 |
|------|----------|----------|
| **透明障碍物** | 落地窗、玻璃门、亚克力茶几 | 多模态融合 + 超声波 + RAG提示 |
| **高动态干扰** | 小孩突然冲出、宠物追逐 | 预测型世界模型，提前规划避让 |
| **长尾物体** | 散落的线缆、透明胶带 | 不确定性回流，主动上传标注 |
| **光照变化** | 窗户强光、夜间低光 | 多曝光融合 + HDR处理 |

---

## 9. 总结

### 9.1 设计精髓

本设计方案围绕具身智能的核心特点，在轮式家庭通用机器人场景下构建了一个以**高价值数据为驱动力**的闭环系统。

**核心理念**：

> **轮式家庭机器人的数据闭环，本质是建立一个"安全受限的后悔最小化"系统：**
> - **后悔**：每一次任务失败、每一次用户不满，都是系统"后悔"的信号
> - **最小化**：通过闭环系统，将这些"后悔"信号高效转化为模型改进的养分
> - **安全受限**：所有学习与进化过程，必须被限制在仿真、影子模式、安全区测试等多重安全闸门之内

### 9.2 系统特点

| 特点 | 说明 |
|------|------|
| **高效数据利用** | F.U.N.原则聚焦高价值数据，避免海量低质数据 |
| **多级安全保障** | 仿真→回放→影子→安全区→灰度的五级部署流程 |
| **隐私内生设计** | 端侧脱敏，原始敏感数据不出家 |
| **可追溯可回滚** | 完整版本管理，支持一键回退 |
| **RAG增强记忆** | 向量化经验库支撑在线检索与持续学习 |

### 9.3 实践建议

> **技术建议**：从"客厅到厨房送水"这个最小可行场景开始，先跑通完整闭环，再逐步扩展能力边界。记住：在家庭场景中，**安全、隐私和信任**比技术指标更重要。

当你的机器人第一次成功避开突然跑过的小孩，当它学会轻柔地拿起易碎的玻璃杯，当它理解"药在抽屉的第二层"这样的指令——这些都不是单次算法突破，而是数据闭环持续进化的结果。

**家庭机器人真正的智能，不在于它能做什么，而在于它如何从错误中变得更懂你的家。**

---

## 附录

### A. 关键术语表

| 术语 | 英文 | 说明 |
|------|------|------|
| VLA | Vision-Language-Action | 视觉-语言-动作模型，机器人"大脑" |
| RAG | Retrieval-Augmented Generation | 检索增强生成，用于场景记忆 |
| Sim2Real | Simulation to Reality | 仿真到现实的迁移 |
| Episode | — | 一个完整的任务片段/数据样本 |
| LoRA | Low-Rank Adaptation | 低秩适配，高效微调方法 |

### B. 参考架构图

```
                    ┌─────────────────────────────────────┐
                    │           云端训练层                │
                    │  ┌─────────┐  ┌─────────┐         │
                    │  │World    │  │VLA      │         │
                    │  │Model    │  │Training │         │
                    │  └────┬────┘  └────┬────┘         │
                    │       │            │               │
                    │  ┌────▼────────────▼────┐         │
                    │  │   Isaac Sim 仿真      │         │
                    │  └──────────────────────┘         │
                    └───────────────┬───────────────────┘
                                    │ 模型包
                    ┌───────────────▼───────────────────┐
                    │          数据枢纽层                │
                    │  ┌─────────┐  ┌─────────┐         │
                    │  │Milvus   │  │MinIO    │         │
                    │  │向量库    │  │对象存储  │         │
                    │  └─────────┘  └─────────┘         │
                    │  ┌─────────────────────┐          │
                    │  │ FastAPI 数据服务    │          │
                    │  └─────────────────────┘          │
                    └───────────────┬───────────────────┘
                                    │ 数据/模型
                    ┌───────────────▼───────────────────┐
                    │           端侧执行层               │
                    │  ┌─────────┐  ┌─────────┐         │
                    │  │ROS 2    │  │TensorRT │         │
                    │  │控制     │  │推理     │         │
                    │  └─────────┘  └─────────┘         │
                    │  ┌─────────────────────┐          │
                    │  │ 智能触发 & 隐私脱敏  │          │
                    │  └─────────────────────┘          │
                    └───────────────┬───────────────────┘
                                    │ 物理交互
                    ┌───────────────▼───────────────────┐
                    │         家庭物理环境               │
                    │     🏠 🪴 🐕 👨‍👩‍👧‍👦 🛋️            │
                    └───────────────────────────────────┘
```

---

*文档版本: v1.0*  
*创建日期: 2025年12月17日*  
*适用范围: 具身智能轮式家庭通用机器人数据闭环系统设计*

